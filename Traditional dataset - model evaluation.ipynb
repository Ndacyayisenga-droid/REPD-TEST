{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paf/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/paf/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/paf/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/paf/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/paf/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/paf/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/paf/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#Data loading\n",
    "from scipy.io import arff\n",
    "#General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import std, mean, sqrt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "#Statistics\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import ttest_ind\n",
    "#Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "#Utility\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paf/miniconda3/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Data preparation\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Classification models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from SmoteEnsemble import SmoteEnsemble as HSME\n",
    "#Result analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score as f1_score_func\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Custom imports\n",
    "from utility import calculate_results\n",
    "from utility import print_confusion_matrix\n",
    "from utility import print_results\n",
    "#\n",
    "from REPD_Impl import REPD\n",
    "from autoencoder import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_pd(matrix):\n",
    "    return matrix[1][1]/(matrix[1][0]+matrix[1][1])\n",
    "\n",
    "def calculate_pf(matrix):\n",
    "    return matrix[0][1]/(matrix[0][0]+matrix[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [\"cm1\",\"jm1\",\"kc1\",\"kc2\",\"pc1\"]\n",
    "dataset_settings = {\n",
    "  \"cm1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ],\n",
    "  \"jm1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ],\n",
    "  \"kc1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ],\n",
    "  \"kc2\": [\"problems\", lambda x: 1 if str(x)==\"b'yes'\" else 0 ],\n",
    "  \"pc1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "episode_count = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm1\n",
      "Running episode  1\n",
      "Running episode  2\n",
      "Running episode  3\n",
      "Running episode  4\n",
      "Running episode  5\n",
      "Running episode  6\n",
      "Running episode  7\n",
      "Running episode  8\n",
      "Running episode  9\n",
      "Running episode  10\n",
      "Running episode  11\n",
      "Running episode  12\n",
      "Running episode  13\n",
      "Running episode  14\n",
      "Running episode  15\n",
      "Running episode  16\n",
      "Running episode  17\n",
      "Running episode  18\n",
      "Running episode  19\n",
      "Running episode  20\n",
      "Running episode  21\n",
      "Running episode  22\n",
      "Running episode  23\n",
      "Running episode  24\n",
      "Running episode  25\n",
      "Running episode  26\n",
      "Running episode  27\n",
      "Running episode  28\n",
      "Running episode  29\n",
      "Running episode  30\n",
      "jm1\n",
      "Running episode  1\n",
      "Running episode  2\n",
      "Running episode  3\n",
      "Running episode  4\n",
      "Running episode  5\n",
      "Running episode  6\n",
      "Running episode  7\n",
      "Running episode  8\n",
      "Running episode  9\n",
      "Running episode  10\n",
      "Running episode  11\n",
      "Running episode  12\n",
      "Running episode  13\n",
      "Running episode  14\n",
      "Running episode  15\n",
      "Running episode  16\n",
      "Running episode  17\n",
      "Running episode  18\n",
      "Running episode  19\n",
      "Running episode  20\n",
      "Running episode  21\n",
      "Running episode  22\n",
      "Running episode  23\n",
      "Running episode  24\n",
      "Running episode  25\n",
      "Running episode  26\n",
      "Running episode  27\n",
      "Running episode  28\n",
      "Running episode  29\n",
      "Running episode  30\n",
      "kc1\n",
      "Running episode  1\n",
      "Running episode  2\n",
      "Running episode  3\n",
      "Running episode  4\n",
      "Running episode  5\n",
      "Running episode  6\n",
      "Running episode  7\n",
      "Running episode  8\n",
      "Running episode  9\n",
      "Running episode  10\n",
      "Running episode  11\n",
      "Running episode  12\n",
      "Running episode  13\n",
      "Running episode  14\n",
      "Running episode  15\n",
      "Running episode  16\n",
      "Running episode  17\n",
      "Running episode  18\n",
      "Running episode  19\n",
      "Running episode  20\n",
      "Running episode  21\n",
      "Running episode  22\n",
      "Running episode  23\n",
      "Running episode  24\n",
      "Running episode  25\n",
      "Running episode  26\n",
      "Running episode  27\n",
      "Running episode  28\n",
      "Running episode  29\n",
      "Running episode  30\n",
      "kc2\n",
      "Running episode  1\n",
      "Running episode  2\n",
      "Running episode  3\n",
      "Running episode  4\n",
      "Running episode  5\n",
      "Running episode  6\n",
      "Running episode  7\n",
      "Running episode  8\n",
      "Running episode  9\n",
      "Running episode  10\n",
      "Running episode  11\n",
      "Running episode  12\n",
      "Running episode  13\n",
      "Running episode  14\n",
      "Running episode  15\n",
      "Running episode  16\n",
      "Running episode  17\n",
      "Running episode  18\n",
      "Running episode  19\n",
      "Running episode  20\n",
      "Running episode  21\n",
      "Running episode  22\n",
      "Running episode  23\n",
      "Running episode  24\n",
      "Running episode  25\n",
      "Running episode  26\n",
      "Running episode  27\n",
      "Running episode  28\n",
      "Running episode  29\n",
      "Running episode  30\n",
      "pc1\n",
      "Running episode  1\n",
      "Running episode  2\n",
      "Running episode  3\n",
      "Running episode  4\n",
      "Running episode  5\n",
      "Running episode  6\n",
      "Running episode  7\n",
      "Running episode  8\n",
      "Running episode  9\n",
      "Running episode  10\n",
      "Running episode  11\n",
      "Running episode  12\n",
      "Running episode  13\n",
      "Running episode  14\n",
      "Running episode  15\n",
      "Running episode  16\n",
      "Running episode  17\n",
      "Running episode  18\n",
      "Running episode  19\n",
      "Running episode  20\n",
      "Running episode  21\n",
      "Running episode  22\n",
      "Running episode  23\n",
      "Running episode  24\n",
      "Running episode  25\n",
      "Running episode  26\n",
      "Running episode  27\n",
      "Running episode  28\n",
      "Running episode  29\n",
      "Running episode  30\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    defect_column_name = dataset_settings[dataset][0]\n",
    "    defect_column_map_function = dataset_settings[dataset][1]\n",
    "\n",
    "    # Load dataset\n",
    "    data, meta = arff.loadarff(\"./data/\"+dataset+\".arff\")\n",
    "\n",
    "    # Wrap data into a pandas dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    #Adjust defects column\n",
    "    df[defect_column_name] = df[defect_column_name].map(defect_column_map_function)\n",
    "\n",
    "    #Remove all with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    #Remove duplicate instances\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #Calculate dataset property constants\n",
    "    total_count = len(df)\n",
    "    non_defective_count = len(df[df[defect_column_name]==0])\n",
    "    defective_count = len(df[df[defect_column_name]==1])\n",
    "    total_count = len(df)\n",
    "    non_defective_count = len(df[df[defect_column_name]==0])\n",
    "    defective_count = len(df[df[defect_column_name]==1])\n",
    "\n",
    "    #Run experiment\n",
    "\n",
    "    X = df.drop(columns=[defect_column_name]).values\n",
    "    y = df[defect_column_name].values\n",
    "\n",
    "    performance_data = []\n",
    "\n",
    "    #Run all the models in the experiment\n",
    "    for experiment_episode in range(1,episode_count+1,1):\n",
    "        print(\"Running episode \", experiment_episode)\n",
    "\n",
    "        #Test train split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        #REPD===========================================================================================\n",
    "        autoencoder = AutoEncoder([21,10],0.01,100,50)\n",
    "        classifer = REPD(autoencoder)\n",
    "        classifer.fit(X_train,y_train)\n",
    "        y_p = classifer.predict(X_test)\n",
    "        matrix, accuracy, precision, recall, f1_score = calculate_results(y_test,y_p)\n",
    "        PD = calculate_pd(matrix)\n",
    "        PF = calculate_pf(matrix)\n",
    "        accuracy = balanced_accuracy_score(y_test,y_p)\n",
    "\n",
    "        #Store results\n",
    "        data = ['REPD',accuracy, precision, recall, f1_score,PD,PF]\n",
    "        performance_data.append(data)\n",
    "\n",
    "        #Close\n",
    "        autoencoder.close()\n",
    "        #GaussianNB===============================================================================================\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_p = classifier.predict(X_test)\n",
    "        matrix, accuracy, precision, recall, f1_score = calculate_results(y_test,y_p)\n",
    "        PD = calculate_pd(matrix)\n",
    "        PF = calculate_pf(matrix)\n",
    "        accuracy = balanced_accuracy_score(y_test,y_p)\n",
    "\n",
    "        #Store results\n",
    "        data = ['GaussianNB',accuracy, precision, recall, f1_score,PD,PF]\n",
    "        performance_data.append(data)\n",
    "        #LogisticRegression===========================================================================================\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_p = classifier.predict(X_test)\n",
    "        matrix, accuracy, precision, recall, f1_score = calculate_results(y_test,y_p)\n",
    "        PD = calculate_pd(matrix)\n",
    "        PF = calculate_pf(matrix)\n",
    "        accuracy = balanced_accuracy_score(y_test,y_p)\n",
    "\n",
    "        #Store results\n",
    "        data = ['LogisticRegression',accuracy, precision, recall, f1_score,PD,PF]\n",
    "        performance_data.append(data)\n",
    "        #KNeighborsClassifier=========================================================================================\n",
    "        classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_p = classifier.predict(X_test)\n",
    "        matrix, accuracy, precision, recall, f1_score = calculate_results(y_test,y_p)\n",
    "        PD = calculate_pd(matrix)\n",
    "        PF = calculate_pf(matrix)\n",
    "        accuracy = balanced_accuracy_score(y_test,y_p)\n",
    "\n",
    "        #Store results\n",
    "        data = ['KNeighborsClassifier',accuracy, precision, recall, f1_score,PD,PF]\n",
    "        performance_data.append(data)\n",
    "\n",
    "        #DecisionTreeClassifier=======================================================================================\n",
    "        classifier = DecisionTreeClassifier()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_p = classifier.predict(X_test)\n",
    "        matrix, accuracy, precision, recall, f1_score = calculate_results(y_test,y_p)\n",
    "        PD = calculate_pd(matrix)\n",
    "        PF = calculate_pf(matrix)\n",
    "        accuracy = balanced_accuracy_score(y_test,y_p)\n",
    "\n",
    "        #Store results\n",
    "        data = ['DecisionTreeClassifier',accuracy, precision, recall, f1_score,PD,PF]\n",
    "        performance_data.append(data)\n",
    "        #HSME=======================================================================================\n",
    "        classifier = HSME()\n",
    "        classifier.fit(X_train,y_train)\n",
    "        y_p = classifier.predict(X_test)\n",
    "        matrix, accuracy, precision, recall, f1_score = calculate_results(y_test,y_p)\n",
    "        PD = calculate_pd(matrix)\n",
    "        PF = calculate_pf(matrix)\n",
    "        accuracy = balanced_accuracy_score(y_test,y_p)\n",
    "\n",
    "        #Store results\n",
    "        data = ['HSME',accuracy, precision, recall, f1_score,PD,PF]\n",
    "        performance_data.append(data)\n",
    "        #=============================================================================================================\n",
    "\n",
    "    results_df = pd.DataFrame(performance_data, columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 score','PD','PF'])\n",
    "    results_df.to_csv(\"results/\"+dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
