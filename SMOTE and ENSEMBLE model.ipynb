{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "#\n",
    "from scipy.io import arff\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#\n",
    "from tabulate import tabulate\n",
    "#\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#\n",
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasets = [\"cm1\",\"jm1\",\"kc1\",\"kc2\",\"pc1\"]\n",
    "dataset_settings = {\n",
    "  \"cm1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ],\n",
    "  \"jm1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ],\n",
    "  \"kc1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ],\n",
    "  \"kc2\": [\"problems\", lambda x: 1 if str(x)==\"b'yes'\" else 0 ],\n",
    "  \"pc1\": [\"defects\", lambda x: 1 if str(x)==\"b'true'\" else 0 ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading:  cm1\n",
      "Loading:  jm1\n",
      "Loading:  kc1\n",
      "Loading:  kc2\n",
      "Loading:  pc1\n"
     ]
    }
   ],
   "source": [
    "X = dict()\n",
    "y = dict()\n",
    "for dataset in datasets:\n",
    "    print(\"Loading: \", dataset)\n",
    "    defect_column_name = dataset_settings[dataset][0]\n",
    "    defect_column_map_function = dataset_settings[dataset][1]\n",
    "\n",
    "    # Load dataset\n",
    "    data, meta = arff.loadarff(\"./data/\"+dataset+\".arff\")\n",
    "\n",
    "    # Wrap data into a pandas dataframe\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    #Adjust defects column\n",
    "    df[defect_column_name] = df[defect_column_name].map(defect_column_map_function)\n",
    "\n",
    "    #Remove all with missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    #Remove duplicate instances\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    #Calculate dataset property constants\n",
    "    total_count = len(df)\n",
    "    non_defective_count = len(df[df[defect_column_name]==0])\n",
    "    defective_count = len(df[df[defect_column_name]==1])\n",
    "    total_count = len(df)\n",
    "    non_defective_count = len(df[df[defect_column_name]==0])\n",
    "    defective_count = len(df[df[defect_column_name]==1])\n",
    "\n",
    "    #Run experiment\n",
    "\n",
    "    X[dataset] = df.drop(columns=[defect_column_name]).values\n",
    "    y[dataset] = df[defect_column_name].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "            (\"Ada\",AdaBoostClassifier()),\n",
    "            (\"Bagging\",BaggingClassifier(base_estimator=DecisionTreeClassifier())),\n",
    "            (\"RandomForest\",RandomForestClassifier())\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tFor dataset cm1 the best model is Ada having F1 0.2\n",
      "\tFor dataset jm1 the best model is Bagging having F1 0.29333333333333333\n",
      "\tFor dataset kc1 the best model is Ada having F1 0.3571428571428572\n",
      "\tFor dataset kc2 the best model is Bagging having F1 0.4324324324324324\n",
      "\tFor dataset pc1 the best model is Bagging having F1 0.22222222222222224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "#\n",
    "REPEAT = 1\n",
    "#\n",
    "best_model = dict()\n",
    "for dataset in datasets:\n",
    "    best_model[dataset] = dict()\n",
    "    for name, _ in models:\n",
    "        best_model[dataset][name] = 0\n",
    "#\n",
    "for i in range(REPEAT):\n",
    "    print(\"Epoch\",i)\n",
    "    for dataset in datasets:\n",
    "        best = \"\"\n",
    "        best_f1 = -1\n",
    "        #\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[dataset], y[dataset], test_size=0.2)\n",
    "        #\n",
    "        for name, model in models:\n",
    "            model.fit(X_train,y_train)\n",
    "            #\n",
    "            y_pred = model.predict(X_test)\n",
    "            #\n",
    "            f1 = f1_score(y_test,y_pred)\n",
    "            #\n",
    "            if f1>best_f1:\n",
    "                best_f1 = f1\n",
    "                best = name\n",
    "        #\n",
    "        print(\"\\tFor dataset\",dataset,\"the best model is\",best,\"having F1\",best_f1)\n",
    "        best_model[dataset][best] = best_model[dataset][best] + 1     \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ada': 1, 'Bagging': 0, 'RandomForest': 0}\n",
      "{'Ada': 0, 'Bagging': 1, 'RandomForest': 0}\n",
      "{'Ada': 1, 'Bagging': 0, 'RandomForest': 0}\n",
      "{'Ada': 0, 'Bagging': 1, 'RandomForest': 0}\n",
      "{'Ada': 0, 'Bagging': 1, 'RandomForest': 0}\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(best_model[dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    best = ''\n",
    "    max_count = 0\n",
    "    for model_name in best_model[dataset]:\n",
    "        count = best_model[dataset][model_name]\n",
    "        if max_count < count:\n",
    "            max_count = count\n",
    "            best = model_name\n",
    "    best_model[dataset] = best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfrom SMOTE on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Xs = dict()\n",
    "#ys = dict()\n",
    "##\n",
    "#for dataset in datasets:\n",
    "#    Xs[dataset], ys[dataset] = sm.fit_resample(X[dataset], y[dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best model on the oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg(l):\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performance_data = dict()\n",
    "for dataset in datasets:\n",
    "    performance_data[dataset] = []\n",
    "REPEAT = 30\n",
    "for i in range(REPEAT):\n",
    "    for dataset in datasets:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X[dataset], y[dataset], test_size=0.2)\n",
    "        #\n",
    "        sm = SMOTE()\n",
    "        X_train, y_train = sm.fit_resample(X_train,y_train)\n",
    "        #\n",
    "        model = None\n",
    "        if best_model[dataset]==\"Ada\":\n",
    "            model = AdaBoostClassifier()\n",
    "        elif best_model[dataset]==\"Bagging\":\n",
    "            model = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "        elif best_model[dataset]==\"RandomForest\":\n",
    "            model = RandomForestClassifier()\n",
    "        #\n",
    "        model.fit(X_train,y_train)\n",
    "        #\n",
    "        y_pred = model.predict(X_test)\n",
    "        #\n",
    "        f1 = f1_score(y_test,y_pred)\n",
    "        #\n",
    "        performance_data[dataset].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cm1 F1 score\n",
      "\t 0.2722158328147624\n",
      "jm1 F1 score\n",
      "\t 0.35286602431562497\n",
      "kc1 F1 score\n",
      "\t 0.40635381673021903\n",
      "kc2 F1 score\n",
      "\t 0.5181199391878842\n",
      "pc1 F1 score\n",
      "\t 0.30121339319251705\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(dataset,\"F1 score\\n\\t\",avg(performance_data[dataset]))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
