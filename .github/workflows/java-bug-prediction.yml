name: Java Bug Prediction Analysis

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - '**/*.java'

jobs:
  bug-prediction:
    runs-on: ubuntu-latest

    permissions:
      contents: read
      pull-requests: write

    steps:
    - name: Checkout PR branch
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
        ref: ${{ github.event.pull_request.head.sha }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Set up Java
      uses: actions/setup-java@v4
      with:
        distribution: 'temurin'
        java-version: '11'
        
    - name: Verify Java installation
      run: |
        java -version
        echo "Java home: $JAVA_HOME"

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install numpy pandas scikit-learn==1.7.1 tensorflow torch scipy tqdm
        pip install -r requirements.txt || {
          echo "Failed to install with specific versions, trying with compatible versions..."
          pip install numpy pandas scikit-learn tensorflow torch scipy tqdm
          pip install -r requirements.txt
        }
        
    - name: Verify AST encoder setup
      run: |
        echo "Checking AST encoder setup..."
        ls -la semantic-dataset-creation/
        ls -la semantic-dataset-creation/config/
        echo "AST encoder JAR exists: $([ -f "semantic-dataset-creation/ASTEncoder-v1.2.jar" ] && echo "YES" || echo "NO")"
        echo "Config files exist: $([ -f "semantic-dataset-creation/config/parser.properties" ] && echo "YES" || echo "NO")"
        
    - name: Verify trained models
      run: |
        echo "Checking trained models..."
        ls -la trained_models/
        echo "Models exist:"
        echo "  DA: $([ -f "trained_models/repd_model_DA.pkl" ] && echo "YES" || echo "NO")"
        echo "  Training results: $([ -f "trained_models/training_results.pkl" ] && echo "YES" || echo "NO")"
        
    - name: Run component tests
      run: |
        echo "Running component tests..."
        python test_workflow.py

    - name: Get changed Java files
      id: changed-files
      run: |
        git diff --name-only origin/${{ github.base_ref }}..HEAD | grep '\.java$' > changed_files.txt || true

        echo "Debug: Checking for changed files..."
        echo "Current directory: $(pwd)"
        echo "Git diff command output:"
        git diff --name-only origin/${{ github.base_ref }}..HEAD || echo "Git diff failed"
        echo "Changed files content:"
        cat changed_files.txt || echo "No changed_files.txt found"

        if [ ! -s changed_files.txt ]; then
          echo "No changed Java files found, looking for any Java files in repository..."
          find . -name "*.java" -type f > changed_files.txt || true
          echo "Found Java files in repository:"
          cat changed_files.txt || echo "No Java files found in repository"
        fi

        if [ -s changed_files.txt ]; then
          echo "changed_files_exist=true" >> $GITHUB_OUTPUT
          echo "Java files to analyze:"
          cat changed_files.txt

          echo "CHANGED_FILES<<EOF" >> $GITHUB_ENV
          cat changed_files.txt
          echo "EOF" >> $GITHUB_ENV
        else
          echo "changed_files_exist=false" >> $GITHUB_OUTPUT
          echo "No Java files found in this PR or repository"
        fi

    - name: Analyze BEFORE state (base branch)
      if: steps.changed-files.outputs.changed_files_exist == 'true'
      run: |
        echo "Analyzing BEFORE state (base branch)..."
        
        git stash push -m "Stash current changes"
        git checkout origin/${{ github.base_ref }}
        
        echo "$CHANGED_FILES" > files_to_analyze.txt
        existing_files=()
        while IFS= read -r file; do
          if [ -f "$file" ]; then
            existing_files+=("$file")
          fi
        done < files_to_analyze.txt

        if [ ${#existing_files[@]} -gt 0 ]; then
          echo "Analyzing BEFORE state for files: ${existing_files[*]}"
          python -u bug_prediction_pipeline.py --files "${existing_files[@]}" --output before_analysis_results --report 2>&1 || {
            echo "Before analysis failed, trying simple predictor..."
            python -u simple_bug_predictor.py --files "${existing_files[@]}" --output before_analysis_results || {
              echo "Creating empty before results"
              mkdir -p before_analysis_results
              echo "Before analysis failed" > before_analysis_results/error.txt
            }
          }
        else
          echo "No files to analyze in base branch"
          mkdir -p before_analysis_results
          echo "No files found in base branch" > before_analysis_results/error.txt
        fi
        
        git checkout -
        git stash pop || echo "No stash to pop"

    - name: Analyze AFTER state (current branch)
      if: steps.changed-files.outputs.changed_files_exist == 'true'
      run: |
        echo "$CHANGED_FILES" > files_to_analyze.txt

        existing_files=()
        while IFS= read -r file; do
          if [ -f "$file" ]; then
            existing_files+=("$file")
          fi
        done < files_to_analyze.txt

        echo "Debug: AFTER state analysis"
        echo "Files to analyze content:"
        cat files_to_analyze.txt || echo "No files_to_analyze.txt found"
        echo "CHANGED_FILES environment variable:"
        echo "$CHANGED_FILES"
        echo "Number of existing files: ${#existing_files[@]}"
        echo "Existing files: ${existing_files[*]}"

        if [ ${#existing_files[@]} -gt 0 ]; then
          echo "Analyzing AFTER state for files: ${existing_files[*]}"
          echo "Number of files to analyze: ${#existing_files[@]}"
          echo "Current working directory: $(pwd)"
          echo "Files exist check:"
          for file in "${existing_files[@]}"; do
            echo "  $file: $([ -f "$file" ] && echo "EXISTS" || echo "MISSING")"
          done
          echo "Running bug prediction pipeline..."
          echo "Command: python bug_prediction_pipeline.py --files ${existing_files[*]} --output after_analysis_results --report"
          
          python -u bug_prediction_pipeline.py --files "${existing_files[@]}" --output after_analysis_results --report 2>&1 || {
            echo "Main analysis failed with exit code $?"
            echo "Trying simple bug predictor as fallback..."
            python -u simple_bug_predictor.py --files "${existing_files[@]}" --output after_analysis_results || {
              echo "Simple predictor also failed, creating empty results directory"
              mkdir -p after_analysis_results
              echo "Analysis failed - check logs for details" > after_analysis_results/error.txt
            }
          }
          
          echo "Checking AFTER results directory..."
          ls -la after_analysis_results/ || echo "Results directory not created"
        else
          echo "No existing Java files to analyze"
          
          echo "Trying fallback: analyzing any Java files in repository..."
          fallback_files=($(find . -name "*.java" -type f | head -5))
          if [ ${#fallback_files[@]} -gt 0 ]; then
            echo "Found fallback files: ${fallback_files[*]}"
            echo "Testing with first fallback file: ${fallback_files[0]}"
            python -u simple_bug_predictor.py --files "${fallback_files[0]}" --output after_analysis_results || {
              echo "Fallback analysis also failed"
              mkdir -p after_analysis_results
              echo "Analysis failed - no files could be processed" > after_analysis_results/error.txt
            }
          else
            echo "No Java files found for fallback analysis"
            mkdir -p after_analysis_results
            echo "No Java files found to analyze" > after_analysis_results/error.txt
          fi
        fi

    - name: Ensure results directory exists
      run: |
        mkdir -p before_analysis_results || true
        mkdir -p after_analysis_results || true
        
        if [ ! -f "before_analysis_results/error.txt" ] && [ ! -f "before_analysis_results/*_DA_predictions.csv" ]; then
          echo "No before analysis results found, creating error file"
          echo "No analysis results available for base branch" > before_analysis_results/error.txt
        fi
        
        if [ ! -f "after_analysis_results/error.txt" ] && [ ! -f "after_analysis_results/*_DA_predictions.csv" ]; then
          echo "No after analysis results found, creating error file"
          echo "No analysis results available for current branch" > after_analysis_results/error.txt
        fi

    - name: Generate PR comment with comparison
      run: |
        echo "Generating PR comment with before/after comparison..."
        echo "Current directory: $(pwd)"
        echo "Before results directory contents:"
        ls -la before_analysis_results/ || echo "Before results directory not found"
        echo "After results directory contents:"
        ls -la after_analysis_results/ || echo "After results directory not found"
        
        if [ ! -d "before_analysis_results" ]; then
          echo "No before results directory found, creating error comment"
          mkdir -p before_analysis_results
          echo "Analysis failed - no before results generated" > before_analysis_results/error.txt
        fi
        
        if [ ! -d "after_analysis_results" ]; then
          echo "No after results directory found, creating error comment"
          mkdir -p after_analysis_results
          echo "Analysis failed - no after results generated" > after_analysis_results/error.txt
        fi
        
        python << 'EOF'
        import os
        import json
        import pandas as pd
        import numpy as np
        from pathlib import Path

        def load_prediction_data(results_dir):
            if not os.path.exists(results_dir):
                return None, None
                
            prediction_files = list(Path(results_dir).glob("*_DA_predictions.csv"))
            summary_files = list(Path(results_dir).glob("*_prediction_summary.json"))
            
            predictions_df = None
            summary_data = {}
            
            if prediction_files:
                try:
                    predictions_df = pd.read_csv(prediction_files[0])
                except Exception as e:
                    print(f"Error loading predictions from {prediction_files[0]}: {e}")
            
            if summary_files:
                try:
                    with open(summary_files[0], 'r') as f:
                        summary_data = json.load(f)
                except Exception as e:
                    print(f"Error loading summary from {summary_files[0]}: {e}")
                    
            return predictions_df, summary_data

        def generate_comparison_comment():
            before_results_dir = "before_analysis_results"
            after_results_dir = "after_analysis_results"

            before_df, before_summary = load_prediction_data(before_results_dir)
            after_df, after_summary = load_prediction_data(after_results_dir)

            comment_lines = [
                "## üìä Bug Prediction Analysis",
                ""
            ]

            has_before = before_df is not None and len(before_df) > 0
            has_after = after_df is not None and len(after_df) > 0

            if not has_before and not has_after:
                comment_lines.extend([
                    "‚ö†Ô∏è **No analysis data available**",
                    "",
                    "Unable to perform before/after comparison - no prediction data found.",
                    "This may indicate an issue with the analysis process."
                ])
                return "\n".join(comment_lines)

            if not has_before:
                comment_lines.extend([
                    "‚ö†Ô∏è **Before state analysis unavailable**",
                    "",
                    "Only current state analysis is available.",
                    "Files may be newly added in this PR."
                ])
                return generate_single_state_comment(after_df, after_summary, "Current State")

            if not has_after:
                comment_lines.extend([
                    "‚ö†Ô∏è **After state analysis unavailable**",
                    "",
                    "Only base branch analysis is available.",
                    "Files may have been deleted in this PR."
                ])
                return "\n".join(comment_lines)

            # Debug: Print available columns
            print("DEBUG: Before DataFrame columns:", before_df.columns.tolist() if before_df is not None else "None")
            print("DEBUG: After DataFrame columns:", after_df.columns.tolist() if after_df is not None else "None")
            print("DEBUG: Before DataFrame shape:", before_df.shape if before_df is not None else "None")
            print("DEBUG: After DataFrame shape:", after_df.shape if after_df is not None else "None")

            if 'file_path' in before_df.columns and 'file_path' in after_df.columns:
                file_col = 'file_path'
            elif 'file_id' in before_df.columns and 'file_id' in after_df.columns:
                file_col = 'file_id'
            else:
                file_col = None

            if file_col:
                before_df_indexed = before_df.set_index(file_col)
                after_df_indexed = after_df.set_index(file_col)
                
                common_files = set(before_df_indexed.index) & set(after_df_indexed.index)
                
                if common_files:
                    for file_path in sorted(common_files):
                        # Use probability_defective instead of pdf_defective
                        before_prob_defective = before_df_indexed.loc[file_path, 'probability_defective']
                        after_prob_defective = after_df_indexed.loc[file_path, 'probability_defective']
                        
                        # Calculate non-defective probabilities
                        before_prob_non_defective = 1.0 - before_prob_defective
                        after_prob_non_defective = 1.0 - after_prob_defective
                        
                        before_pred = before_df_indexed.loc[file_path, 'prediction']
                        after_pred = after_df_indexed.loc[file_path, 'prediction']
                        
                        # Calculate percentage changes
                        if before_prob_defective > 0:
                            def_change = ((after_prob_defective - before_prob_defective) / before_prob_defective) * 100
                        else:
                            def_change = float('inf') if after_prob_defective > 0 else 0
                        
                        if before_prob_non_defective > 0:
                            non_change = ((after_prob_non_defective - before_prob_non_defective) / before_prob_non_defective) * 100
                        else:
                            non_change = float('inf') if after_prob_non_defective > 0 else 0
                        
                        before_status = "Defective" if before_pred == 1 else "Non-Defective"
                        after_status = "Defective" if after_pred == 1 else "Non-Defective"
                        
                        display_name = file_path
                        
                        comment_lines.extend([
                            f"File: {display_name}",
                            f"Outcome: {before_status} -> {after_status}",
                            "",
                            "| Metric | BEFORE PR | AFTER PR | % Change |",
                            "|--------|-----------|----------|----------|"
                        ])
                        
                        # Format in scientific notation
                        before_def_sci = f"{before_prob_defective:.5e}"
                        after_def_sci = f"{after_prob_defective:.5e}"
                        before_non_sci = f"{before_prob_non_defective:.5e}"
                        after_non_sci = f"{after_prob_non_defective:.5e}"
                        
                        # Format percentage changes
                        if def_change == float('inf'):
                            def_change_str = "+‚àû%"
                        elif def_change == 0:
                            def_change_str = "0%"
                        else:
                            def_change_str = f"{def_change:+.2f}%"
                        
                        if non_change == float('inf'):
                            non_change_str = "+‚àû%"
                        elif non_change == 0:
                            non_change_str = "0%"
                        else:
                            non_change_str = f"{non_change:+.2f}%"
                        
                        comment_lines.extend([
                            f"| PDF(Defective \\| Reconstruction Error) | {before_def_sci} | {after_def_sci} | {def_change_str} |",
                            f"| PDF(Non-Defective \\| Reconstruction Error) | {before_non_sci} | {after_non_sci} | {non_change_str} |",
                            ""
                        ])
                else:
                    comment_lines.append("No common files found for comparison.")
            else:
                # Fallback: assume same order and compare by index
                min_len = min(len(before_df), len(after_df))
                for i in range(min_len):
                    # Use probability_defective instead of pdf_defective
                    before_prob_defective = before_df.iloc[i]['probability_defective']
                    after_prob_defective = after_df.iloc[i]['probability_defective']
                    
                    # Calculate non-defective probabilities
                    before_prob_non_defective = 1.0 - before_prob_defective
                    after_prob_non_defective = 1.0 - after_prob_defective
                    
                    before_pred = before_df.iloc[i]['prediction']
                    after_pred = after_df.iloc[i]['prediction']
                    
                    # Calculate percentage changes
                    if before_prob_defective > 0:
                        def_change = ((after_prob_defective - before_prob_defective) / before_prob_defective) * 100
                    else:
                        def_change = float('inf') if after_prob_defective > 0 else 0
                    
                    if before_prob_non_defective > 0:
                        non_change = ((after_prob_non_defective - before_prob_non_defective) / before_prob_non_defective) * 100
                    else:
                        non_change = float('inf') if after_prob_non_defective > 0 else 0
                    
                    before_status = "Defective" if before_pred == 1 else "Non-Defective"
                    after_status = "Defective" if after_pred == 1 else "Non-Defective"
                    
                    # Get file name
                    file_name = "Unknown"
                    if 'file_path' in before_df.columns:
                        file_name = before_df.iloc[i]['file_path']
                    elif 'file_id' in before_df.columns:
                        file_name = before_df.iloc[i]['file_id']
                    else:
                        file_name = f"File_{i+1}.java"
                    
                    comment_lines.extend([
                        f"File: {file_name}",
                        f"Outcome: {before_status} -> {after_status}",
                        "",
                        "| Metric | BEFORE PR | AFTER PR | % Change |",
                        "|--------|-----------|----------|----------|"
                    ])
                    
                    # Format in scientific notation
                    before_def_sci = f"{before_prob_defective:.5e}"
                    after_def_sci = f"{after_prob_defective:.5e}"
                    before_non_sci = f"{before_prob_non_defective:.5e}"
                    after_non_sci = f"{after_prob_non_defective:.5e}"
                    
                    # Format percentage changes
                    if def_change == float('inf'):
                        def_change_str = "+‚àû%"
                    elif def_change == 0:
                        def_change_str = "0%"
                    else:
                        def_change_str = f"{def_change:+.2f}%"
                    
                    if non_change == float('inf'):
                        non_change_str = "+‚àû%"
                    elif non_change == 0:
                        non_change_str = "0%"
                    else:
                        non_change_str = f"{non_change:+.2f}%"
                    
                    comment_lines.extend([
                        f"| PDF(Defective \\| Reconstruction Error) | {before_def_sci} | {after_def_sci} | {def_change_str} |",
                        f"| PDF(Non-Defective \\| Reconstruction Error) | {before_non_sci} | {after_non_sci} | {non_change_str} |",
                        ""
                    ])

            return "\n".join(comment_lines)

        def generate_single_state_comment(df, summary_data, state_name):
            comment_lines = [
                f"## Bug Prediction Analysis - {state_name}",
                ""
            ]

            if df is not None and len(df) > 0:
                defective_count = (df['prediction'] == 1).sum()
                defect_rate = (defective_count / len(df)) * 100
                # Use probability_defective instead of pdf_defective
                avg_prob_defective = df['probability_defective'].mean()

                comment_lines.extend([
                    f"üìä **Files Analyzed:** {len(df)}",
                    "",
                    "### üî¨ Analysis Results",
                    "",
                    f"- **Predicted Defective:** {defective_count}/{len(df)} files ({defect_rate:.1f}%)",
                    f"- **Average Probability Defective:** {avg_prob_defective:.4e}",
                    ""
                ])

                # Use probability_defective for sorting
                top_risky = df.nlargest(min(3, len(df)), 'probability_defective')
                if len(top_risky) > 0:
                    comment_lines.extend([
                        "**üö® Top Risky Files:**",
                        "",
                        "| File | Probability Defective | Status |",
                        "|------|----------------------|--------|"
                    ])

                    for _, row in top_risky.iterrows():
                        file_name = row.get('file_path', row.get('file_id', 'Unknown'))
                        if isinstance(file_name, str) and len(file_name) > 50:
                            file_name = "..." + file_name[-47:]

                        # Use probability_defective instead of pdf_defective
                        prob = row['probability_defective']
                        status = "üî¥ High Risk" if prob > 0.5 else "üü¢ Low Risk"
                        comment_lines.append(f"| `{file_name}` | {prob:.4e} | {status} |")

            return "\n".join(comment_lines)

        comment_content = generate_comparison_comment()

        with open('pr_comment.md', 'w') as f:
            f.write(comment_content)

        print("Generated PR comment:")
        print("=" * 50)
        print(comment_content)
        EOF

    - name: Post comment to PR
      if: steps.changed-files.outputs.changed_files_exist == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          try {
            const comment = fs.readFileSync('pr_comment.md', 'utf8');

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

            console.log('Successfully posted comment to PR');
          } catch (error) {
            console.error('Error posting comment:', error);

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '## Bug Prediction Analysis\n\n‚ö†Ô∏è **Analysis encountered an error**\n\nPlease check the workflow logs for details.'
            });
          }

    - name: Upload analysis results
      if: steps.changed-files.outputs.changed_files_exist == 'true'
      uses: actions/upload-artifact@v4
      with:
        name: bug-prediction-results
        path: |
          before_analysis_results/
          after_analysis_results/
          pr_comment.md
          changed_files.txt
        retention-days: 30

    - name: Check for high-risk files
      if: steps.changed-files.outputs.changed_files_exist == 'true'
      run: |
        python << 'EOF'
        import os
        import pandas as pd
        from pathlib import Path

        results_dir = "after_analysis_results"
        high_risk_threshold = 0.8

        if os.path.exists(results_dir):
            prediction_files = list(Path(results_dir).glob("*_DA_predictions.csv"))

            high_risk_files = []
            for pred_file in prediction_files:
                try:
                    df = pd.read_csv(pred_file)
                    very_high_risk = df[df['probability_defective'] > high_risk_threshold]
                    if len(very_high_risk) > 0:
                        high_risk_files.extend(very_high_risk['file_path'].tolist() if 'file_path' in very_high_risk.columns else very_high_risk['file_id'].tolist())
                except Exception:
                    pass

            if high_risk_files:
                print(f"::warning::High-risk files detected with >80% defect probability: {', '.join(set(high_risk_files))}")
                print("Consider additional code review and testing for these files.")
            else:
                print("No extremely high-risk files detected.")
                
            before_results_dir = "before_analysis_results"
            if os.path.exists(before_results_dir):
                before_files = list(Path(before_results_dir).glob("*_DA_predictions.csv"))
                after_files = list(Path(results_dir).glob("*_DA_predictions.csv"))
                
                if before_files and after_files:
                    try:
                        before_df = pd.read_csv(before_files[0])
                        after_df = pd.read_csv(after_files[0])
                        
                        before_avg = before_df['probability_defective'].mean()
                        after_avg = after_df['probability_defective'].mean()

                        if after_avg > before_avg:
                            change_pct = ((after_avg - before_avg) / before_avg) * 100
                            if change_pct > 50:
                                print(f"::warning::Significant increase in bug risk detected: {change_pct:.1f}% increase in average defect probability")
                            elif change_pct > 20:
                                print(f"::notice::Moderate increase in bug risk detected: {change_pct:.1f}% increase in average defect probability")
                    except Exception as e:
                        print(f"Could not compare before/after results: {e}")
        EOF